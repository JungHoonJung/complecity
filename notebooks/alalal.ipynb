{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1599465880534",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import shapely.geometry as geom\n",
    "import numpy as np\n",
    "import h5py as h5\n",
    "import taxidata as td\n",
    "import d_curve as dc\n",
    "import ksegment as ks\n",
    "import networkx as nx\n",
    "import ctypes\n",
    "\n",
    "Seoul = td.Roadnetwork()\n",
    "s_elist = gpd.read_file(r'.\\taxidata\\core\\network\\nodelink\\Seoul_Edgelist.csv')\n",
    "s_link = gpd.read_file(r\".\\taxidata\\core\\network\\nodelink\\Seoul_Links.shp\")\n",
    "for l, e in s_elist.iterrows():\n",
    "    geom = s_link['geometry'][int(e['EDGE'])-1]\n",
    "    Seoul.add_edge(int(e['START_NODE']),int(e['END_NODE']),ID = int(e['EDGE']), length = float(e['LENGTH']), geometry = geom)\n",
    "    Seoul.nodes[int(e['START_NODE'])]['pos'] = (float(e['XCoord']),float(e['YCoord']))\n",
    "def angle(G, node1, node2):\n",
    "    '''aspect of node1 as origin, return angle of node2 in sence of polar coordinates.'''\n",
    "    p1 = G.nodes[node1]['pos']\n",
    "    p2 = G.nodes[node2]['pos']\n",
    "    p2_ = (p2[0]-p1[0],p2[1]-p1[1])\n",
    "    return np.arctan2(p2_[1],p2_[0])\n",
    "for edge in Seoul.edges(data = True):\n",
    "    edge[-1]['angle']=angle(Seoul, edge[0],edge[1])\n",
    "    \n",
    "pos = Seoul.pos\n",
    "seoul_dict = dict(Seoul.pos)\n",
    "nodeid = np.array(list(seoul_dict.keys()))\n",
    "nodelist= np.array(list(seoul_dict.values()))\n",
    "data_raw = td.Dataset('2013-12-12.hdf5')\n",
    "taxi_raw = data_raw.get_array(fields=['lat','lon'],num = 1,random = False)\n",
    "taxi = td.toUTM(taxi_raw['lat'],taxi_raw['lon'])\n",
    "points = np.array(taxi).T\n",
    "points_f = points.flatten()\n",
    "points_f=np.array(points_f).astype(np.float32)\n",
    "\n",
    "grid_200 = [[]for j in range(743*734)]\n",
    "for nodepos, nid in zip(nodelist, nodeid):\n",
    "    grid_200_id = nodepos//200 - [1234,20400]\n",
    "    grid_200[int(grid_200_id[0] + grid_200_id[1]*734)].append(nid)\n",
    "\n",
    "#node로 segment 만들기\n",
    "def k(start_node):\n",
    "    seg = td.k_segments_strict_bfs_with_length(Seoul, start_node, 800)\n",
    "    len_seg = len(seg)\n",
    "    list_seg = [[start_node]for l in range(len_seg)]\n",
    "    n = 0\n",
    "    for i in seg:\n",
    "        for j in i.edges():\n",
    "            list_seg[n].append(j[1])\n",
    "        n += 1\n",
    "    return list_seg\n",
    "\n",
    "#nodeid > node좌표\n",
    "def k_xy(start_node):\n",
    "    a = []\n",
    "    for i in k(start_node):\n",
    "        node=np.array([seoul_dict[j] for j in i])\n",
    "        a.append(node)\n",
    "    return a\n",
    "\n",
    "    #trajectory grid set에서 start node 뽑기\n",
    "def start(grid_set):\n",
    "    node = []\n",
    "    for i in grid_set:\n",
    "        node.append(grid_200[i])\n",
    "    return node\n",
    "\n",
    "grid1_set = td.trajectory.grid_set(points)\n",
    "start_set = start(grid1_set)\n",
    "seg_id=[]\n",
    "#start node 세그먼트들의 grid number\n",
    "seg_xy=[]\n",
    "#start node 세그먼트들의 xy\n",
    "for z in start_set:\n",
    "    for j in z:\n",
    "        seg_id.append(td.k_segments_strict_bfs_with_length(Seoul, j, 800))\n",
    "        for i in k_xy(j):\n",
    "            seg_xy.append(i)\n",
    "seg_id=sum(seg_id,[])\n",
    "real_xy=[]\n",
    "real_id=[]\n",
    "for i in range(len(seg_xy)):\n",
    "    if np.isin(td.trajectory.trajectory_grid(seg_xy[i]), grid1_set).all():\n",
    "        real_xy.append(seg_xy[i])\n",
    "        real_id.append(seg_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_id=[]\n",
    "#start node 세그먼트들의 grid number\n",
    "seg_xy=[]\n",
    "#start node 세그먼트들의 xy\n",
    "for z in start_set:\n",
    "    for j in z:\n",
    "        seg_id.append(td.k_segments_strict_bfs_with_length(Seoul, j, 800))\n",
    "        for i in k_xy(j):\n",
    "            seg_xy.append(i)\n",
    "seg_id=sum(seg_id,[])\n",
    "real_xy=[]\n",
    "real_id=[]\n",
    "for i in range(len(seg_xy)):\n",
    "    if np.isin(td.trajectory.trajectory_grid(seg_xy[i]), grid1_set).all():\n",
    "        real_xy.append(seg_xy[i])\n",
    "        real_id.append(seg_id[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ctypes\n",
    "_cdll = ctypes.windll.LoadLibrary(\"./Dll1.dll\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "_cdll.d_curve.argtypes = [np.ctypeslib.ndpointer(dtype=np.float32),\\\n",
    "                          np.ctypeslib.ndpointer(dtype=np.int32),\\\n",
    "                          np.ctypeslib.ndpointer(dtype=np.int32),\\\n",
    "                          ctypes.c_int,\\\n",
    "                          np.ctypeslib.ndpointer(dtype=np.float32),\\\n",
    "                          ctypes.c_int,\\\n",
    "                          ctypes.c_int,\\\n",
    "                          np.ctypeslib.ndpointer(dtype=np.float32),\\\n",
    "                          np.ctypeslib.ndpointer(dtype=np.float32),\\\n",
    "                          ctypes.c_int]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_len=[]\n",
    "seg_start=[]\n",
    "start_init=0\n",
    "for i in real_xy:\n",
    "    seg_start.append(start_init)\n",
    "    seg_len.append(len(i))\n",
    "    start_init+=len(i)\n",
    "    \n",
    "seg_tot=len(real_xy)\n",
    "real_xy = [item for sublist in real_xy for item in sublist]\n",
    "real_xy = [item for sublist in real_xy for item in sublist]\n",
    "\n",
    "traj_len=int(len(points_f)/2)\n",
    "\n",
    "real_xy=np.array(real_xy).astype(np.float32)\n",
    "seg_len=np.array(seg_len).astype(np.int32)\n",
    "seg_start=np.array(seg_start).astype(np.int32)\n",
    "prefix=np.zeros(seg_tot).astype(np.float32)\n",
    "d_c=-np.ones(seg_tot).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Wall time: 4.28 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "d_candi1=_cdll.d_curve(real_xy,seg_len,seg_start,seg_tot,points_f,traj_len,0,prefix,d_c,8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "205640864"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "n=0\n",
    "for i in d_c:\n",
    "    for j in i:\n",
    "        if j==-1:\n",
    "            n+=1\n",
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.0"
     },
     "metadata": {},
     "execution_count": 60
    }
   ],
   "source": [
    "prefix[22469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "-1.0"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "d_c[22469]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('haha',d_c,allow_pickle=False)"
   ]
  }
 ]
}